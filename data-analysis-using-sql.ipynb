{"cells":[{"metadata":{"_cell_guid":"506bd974-9157-4cc8-a410-cabca6a0f459","_uuid":"fac40b1c1c9e035e1b5d31fb5c702a2c7cc799a1","collapsed":true},"cell_type":"markdown","source":"# Motivation\nI'll use this script to provide introduction to data analysis using SQL language, which should be a must tool for every data scientist - both for getting access to data, but more interesting, as a simple tool for advance data analysis.\nThe logic behind SQL is very similar to any other tool or language that used for data analysis (excel, Pandas),  and for those that used to work with data, should be very intuitive. \n\nFeel free to respond with questions, and I'll try to explain more if need."},{"metadata":{"_cell_guid":"581b0fb8-9fe2-475f-a651-1f308d996401","_uuid":"c01b2a7d26a3bc74f8a5fefd5b5e457265e99aab"},"cell_type":"markdown","source":"# Important Definitions\nSQL is a conceptual language for working with data stored in databases. In our case, SQLite is the specific implementation. Most SQL languges share all of the capabilities in this doc. The differences are usually in performance and advances analytical funcionalities (and sometimes bugs of course).\nEventually, we will use SQL lunguage to write queries that would pull data from the DB, manipulate it, sort it, and extract it.\n\nThe most important component of the DB  is its tables - that's where all the data stored. Usually the data would be devided to many tables, and not stored all in one place (so designing the data stracture propely is very important). Most of this script would handle how to work with tables.\nOther than tables, there are some other very useful concepts/features that we won't talk about:\n* table creation\n* inserting / updating data in the DB\n* functions - gets a value as an input, and returns manipulation of that value (for example function that remove white spaces)"},{"metadata":{"_cell_guid":"b24c5690-a816-45cf-b9d2-51a7a9e0a4f5","_kg_hide-input":false,"_uuid":"81e2c6b2403df820374e6c93416d15182c7dc28b","collapsed":true,"trusted":true},"cell_type":"code","source":"#Improts \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport sqlite3\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\npath = \"../input/\"  #Insert path here\ndatabase = path + 'database.sqlite'","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a1904a39-a670-488e-96f6-79a300632f04","_uuid":"2f39df885d6f3a6253eab35a617550780b4e6c04"},"cell_type":"markdown","source":"# First we will create the connection to the DB, and see what tables we have\nThe basic structure of the query is very simple:\nYou define what you want to see after the SELECT, * means all possible columns\nYou choose the table after the FROM\nYou add the conditions for the data you want to use from the table(s) after the WHERE\n\nThe stracture, and the order of the sections matter, while spaces, new lines, capital words and indentation are there to make the code easier to read."},{"metadata":{"_cell_guid":"4cb0a902-99e2-4ad7-a217-87db3950630e","_uuid":"ae3f3b681f48c7c8863999e0434d7ce2f9b43f34","collapsed":true,"trusted":true},"cell_type":"code","source":"conn = sqlite3.connect(database)\n\ntables = pd.read_sql(\"\"\"SELECT *\n                        FROM sqlite_master\n                        WHERE type='table';\"\"\", conn)\ntables","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"1d749faa-7d12-40e1-96ce-de791dd28526","_uuid":"aa75b8d7a97a5e878fb1482c80889abe8b7beb5b"},"cell_type":"markdown","source":"# List of countries\nThis is the most basic query.\nThe only must parts of a qeury is the SELECT and the FROM (assuming you want to pull from a table)"},{"metadata":{"_cell_guid":"e64c0d9b-7999-4458-875c-38a2f0649f6c","_kg_hide-input":false,"_kg_hide-output":false,"_uuid":"de315df5c5a856be24fc96803099f8b0df91f6da","collapsed":true,"trusted":true},"cell_type":"code","source":"countries = pd.read_sql(\"\"\"SELECT *\n                        FROM Country;\"\"\", conn)\ncountries","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"d2e02d44-e124-4558-b3c3-475e7074ae5e","_uuid":"ccccdfdf702455719c9a2d20860c04d8c2fd15cf"},"cell_type":"markdown","source":"# List of leagues and their country \nJOIN is used when you want to connect two tables to each other. It works when you have a common key in each of them.\nUnderstanding the concept of Keys is crucial for connecting (joining) between data set (tables). \nA key is uniquely identifies each record (row) in a table. \nIt can consinst of one value (cell) - usually ID, or from a combination of values that are unique in the table.\n\nWhen joinin between different tables, you must:\n* Decide what type of join to use. The most common are:\n* * (INNER) JOIN - keep only records that match the condition (after the ON) in both the tables, and records in both tables that do not match wouldn't appear in the output\n* * LEFT JOIN - keep all the values from the first (left) table - in conjunction with the matching rows from the right table. The columns from the right table, that don't have matching value in the left, would have NULL values. \n* Specify the common value that is used to connect the tables (the id of the country in that case). \n* Make sure that at least one of the values has to be a key in its table. In our case, it's the Country.id. The League.country_id is not unique, as there can be more than one league in the same country\n\nJOINs, and using them incorrectly, is the most common and dangerious mistake when writing complicated queries"},{"metadata":{"_cell_guid":"9f1f76bf-3870-458d-b092-e00c3719b0f1","_kg_hide-output":false,"_uuid":"633c5dec1f173c077d296af9e589a0abf6cb9396","collapsed":true,"trusted":true},"cell_type":"code","source":"leagues = pd.read_sql(\"\"\"SELECT *\n                        FROM League\n                        JOIN Country ON Country.id = League.country_id;\"\"\", conn)\nleagues","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"2c791a87-1a24-49b8-9e8a-59d6383bdd56","_uuid":"ca37991951b15e842a35ea168273110328e88e7f"},"cell_type":"markdown","source":"# List of teams\nORDER BY defines the sorting of the output - ascending or descending (DESC)\n\nLIMIT, limits the number of rows in the output - after the sorting"},{"metadata":{"_cell_guid":"f2850218-dbfa-432e-874d-af112f399137","_uuid":"1ba6a54bf81ad1c0b1e8348cb2f7cc4365f5953a","collapsed":true,"trusted":true},"cell_type":"code","source":"teams = pd.read_sql(\"\"\"SELECT *\n                        FROM Team\n                        ORDER BY team_long_name\n                        LIMIT 10;\"\"\", conn)\nteams","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"347e4255-340f-434b-9215-91e7fa60019d","_uuid":"8092b006106928451a28d47fd2e93efb26a9ba6c"},"cell_type":"markdown","source":"# List of matches\nIn this exapmle we will show only the columns that interests us, so instead of * we will use the exact names.\n\nSome of the cells have the same name (Country.name,League.name). We will rename them using AS.\n\nAs you can see, this query has much more joins. The reasons is because the DB is designed in a star\nstructure - one table (Match) with all the \"performance\" and metrics, but only keys and IDs,\nwhile all the descriptive information stored in other tables (Country, League, Team)\n\nNote that Team is joined twice. This is a tricky one, as while we are using the same table name, we basically bring two different copies (and rename them using AS). The reason is that we need to bring information about two different values (home_team_api_id, away_team_api_id), and if we join them to the same table, it would mean that they are equal to each other.\n\nYou will also note that the Team tables are joined using left join. The reason is decided that I would prefer to keep the matches in the output - even if on of the teams doesn't appear in the Team table.\n\nORDER defines the order of the output, and comes before the LIMIT and after the WHERE"},{"metadata":{"_cell_guid":"6538dec2-d24f-4310-a010-4f5c630a5bb9","_uuid":"5fcbd2cc7d6ec1545a618a082621e6ffde7fc907","collapsed":true,"trusted":true},"cell_type":"code","source":"detailed_matches = pd.read_sql(\"\"\"SELECT Match.id, \n                                        Country.name AS country_name, \n                                        League.name AS league_name, \n                                        season, \n                                        stage, \n                                        date,\n                                        HT.team_long_name AS  home_team,\n                                        AT.team_long_name AS away_team,\n                                        home_team_goal, \n                                        away_team_goal                                        \n                                FROM Match\n                                JOIN Country on Country.id = Match.country_id\n                                JOIN League on League.id = Match.league_id\n                                LEFT JOIN Team AS HT on HT.team_api_id = Match.home_team_api_id\n                                LEFT JOIN Team AS AT on AT.team_api_id = Match.away_team_api_id\n                                WHERE country_name = 'Spain'\n                                ORDER by date\n                                LIMIT 10;\"\"\", conn)\ndetailed_matches","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"63b4a413-41f5-434c-9ae1-e4b7cc6df717","_uuid":"2df09bf2c111e61a9901f1876617f84dd89627cd"},"cell_type":"markdown","source":"# Let's do some basic analytics\nHere we are starting to look at the data at more aggregated level. Instead of looking on the raw data we will start to grouping it to different levels we want to examine.\nIn this example, we will base it on the previous query, remove the match and date information, and look at it at the country-league-season level.\n\nThe functionality we will use for that is GROUP BY, that comes between the WHERE and ORDER\n\nOnce you chose what level you want to analyse, we can devide the select statement to two:\n* Dimensions - those are the values we describing, same that we group by later.\n* Metrics - all the metrics have to be aggregated using functions.. \nThe common functions are: sum(), count(), count(distinct), avg(), min(), max()\n\nNote - it is very important to use the same dimensions both in the select, and in the GROUP BY. Otherwise the output might be wrong.\n\nAnother functionality that can be used after grouping, is HAVING. This adds another layer of filtering the data, this time the output of the table **after** the grouping. A lot of times it is used to clean the output.\n"},{"metadata":{"_cell_guid":"8b92be20-2e32-472d-8a1d-5a4147d5ea03","_kg_hide-output":false,"_uuid":"57b770e270081fb69e56e896660228ea70a25921","collapsed":true,"trusted":true},"cell_type":"code","source":"leages_by_season = pd.read_sql(\"\"\"SELECT Country.name AS country_name, \n                                        League.name AS league_name, \n                                        season,\n                                        count(distinct stage) AS number_of_stages,\n                                        count(distinct HT.team_long_name) AS number_of_teams,\n                                        avg(home_team_goal) AS avg_home_team_scors, \n                                        avg(away_team_goal) AS avg_away_team_goals, \n                                        avg(home_team_goal-away_team_goal) AS avg_goal_dif, \n                                        avg(home_team_goal+away_team_goal) AS avg_goals, \n                                        sum(home_team_goal+away_team_goal) AS total_goals                                       \n                                FROM Match\n                                JOIN Country on Country.id = Match.country_id\n                                JOIN League on League.id = Match.league_id\n                                LEFT JOIN Team AS HT on HT.team_api_id = Match.home_team_api_id\n                                LEFT JOIN Team AS AT on AT.team_api_id = Match.away_team_api_id\n                                WHERE country_name in ('Spain', 'Germany', 'France', 'Italy', 'England')\n                                GROUP BY Country.name, League.name, season\n                                HAVING count(distinct stage) > 10\n                                ORDER BY Country.name, League.name, season DESC\n                                ;\"\"\", conn)\nleages_by_season","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"6f8b19b2-8559-4656-b182-9b11f59989e8","_kg_hide-input":true,"_uuid":"5bbd68e2a116450427b48743f0da824df9cb8b79","collapsed":true,"trusted":true},"cell_type":"code","source":"df = pd.DataFrame(index=np.sort(leages_by_season['season'].unique()), columns=leages_by_season['country_name'].unique())\n\ndf.loc[:,'Germany'] = list(leages_by_season.loc[leages_by_season['country_name']=='Germany','avg_goals'])\ndf.loc[:,'Spain']   = list(leages_by_season.loc[leages_by_season['country_name']=='Spain','avg_goals'])\ndf.loc[:,'France']   = list(leages_by_season.loc[leages_by_season['country_name']=='France','avg_goals'])\ndf.loc[:,'Italy']   = list(leages_by_season.loc[leages_by_season['country_name']=='Italy','avg_goals'])\ndf.loc[:,'England']   = list(leages_by_season.loc[leages_by_season['country_name']=='England','avg_goals'])\n\ndf.plot(figsize=(12,5),title='Average Goals per Game Over Time')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"f2a75e9a-6653-48b0-9197-cd6359ab6da8","_kg_hide-input":true,"_uuid":"c3c47ee74d74659d2b9b23ad00e0bbef9a0ea5c5","collapsed":true,"trusted":true},"cell_type":"code","source":"df = pd.DataFrame(index=np.sort(leages_by_season['season'].unique()), columns=leages_by_season['country_name'].unique())\n\ndf.loc[:,'Germany'] = list(leages_by_season.loc[leages_by_season['country_name']=='Germany','avg_goal_dif'])\ndf.loc[:,'Spain']   = list(leages_by_season.loc[leages_by_season['country_name']=='Spain','avg_goal_dif'])\ndf.loc[:,'France']   = list(leages_by_season.loc[leages_by_season['country_name']=='France','avg_goal_dif'])\ndf.loc[:,'Italy']   = list(leages_by_season.loc[leages_by_season['country_name']=='Italy','avg_goal_dif'])\ndf.loc[:,'England']   = list(leages_by_season.loc[leages_by_season['country_name']=='England','avg_goal_dif'])\n\ndf.plot(figsize=(12,5),title='Average Goals Difference Home vs Out')","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"dc398357-9a0c-46db-ba76-1f9d07b93b41","_uuid":"dbd4ef350896497e1f11d0023fce9810300a45b2"},"cell_type":"markdown","source":"# Query Run Order\nNow that we are familiar with most of the functionalities being used in a query, it is very important to understand the order that code runs.\n\nFirst, order of how we write it (reminder):\n* SELECT\n* FROM\n* JOIN\n* WHERE\n* GROUP BY\n* HAVING\n* ORDER BY\n* LIMIT\n\nNow, the actul order that things happens.\nFirst, you can think of this part as creating a new temporal table in the memory:\n* Define which tables to use, and connect them (FROM + JOIN)\n* Keep only the rows that apply to the conditions (WHERE)\n* Group the data by the required level (if need) (GROUP BY)\n* Choose what information you want to have in the new table. It can have just rawdata (if no grouping), or combination of dimensions (from the grouping), and metrics\nNow, you chose that to show from the table:\n* Order the output of the new table (ORDER BY)\n* Add more conditions that would filter the new created table (HAVING) \n* Limit to number of rows - would cut it according the soring and the having filtering (LIMIT)\n"},{"metadata":{"_cell_guid":"f17cbfb9-d25c-4597-887a-6114eddda250","_uuid":"fd444f1cf990ec5cc42c889a65cabff0f1353d27"},"cell_type":"markdown","source":"# Sub Queries and Functions \n\nUsing subqueries is an essential tool in SQL, as it allows manipulating the data in very advanced ways without the need of any external scripts, and especially important when your tables stractured in such a way that you can't be joined directly.\n\nIn our example, I'm trying to join between a table that holds player's basic details (name, height, weight), to a table that holds more attributes. The problem is that while the first table holds one row for each player, the key in the second table is player+season, so if we do a regular join, the result would be a Cartesian product, and each player's basic details would appear as many times as this player appears in the attributes table. The problem with of course is that the average would be skewed towards players that appear many times in the attribute table.\n\nThe solution, is to use a subquery.  We would need to group the attributes table, to a different key - player level only (without season). Of course we would need to decide first how we would want to combine all the attributes to a single row. I used average, but one can also decide on maximum, latest season and etc. \nOnce both tables have the same keys, we can join them together (think of the subquery as any other table, only temporal), knowing that we won't have duplicated rows after the join.\n\nIn addition, you can see here two examples of how to use functions:\n* Conditional function is an important tool for data manipulation. While IF statement is very popular in other languages, SQLite is not supporting it, and it's implemented using CASE + WHEN + ELSE statement. \nAs you can see, based on the input of the data, the query would return different results.\n\n* ROUND - straight sorward.\nEvery SQL languages comes with a lot of usefull functions by default."},{"metadata":{"_cell_guid":"cda7c6ea-33af-4155-a2fa-93548aef12e7","_kg_hide-input":false,"_kg_hide-output":false,"_uuid":"c0620891169bb5ea3d0de4f800737f40a93c6b03","collapsed":true,"trusted":true},"cell_type":"code","source":"players_height = pd.read_sql(\"\"\"SELECT CASE\n                                        WHEN ROUND(height)<165 then 165\n                                        WHEN ROUND(height)>195 then 195\n                                        ELSE ROUND(height)\n                                        END AS calc_height, \n                                        COUNT(height) AS distribution, \n                                        (avg(PA_Grouped.avg_overall_rating)) AS avg_overall_rating,\n                                        (avg(PA_Grouped.avg_potential)) AS avg_potential,\n                                        AVG(weight) AS avg_weight \n                            FROM PLAYER\n                            LEFT JOIN (SELECT Player_Attributes.player_api_id, \n                                        avg(Player_Attributes.overall_rating) AS avg_overall_rating,\n                                        avg(Player_Attributes.potential) AS avg_potential  \n                                        FROM Player_Attributes\n                                        GROUP BY Player_Attributes.player_api_id) \n                                        AS PA_Grouped ON PLAYER.player_api_id = PA_Grouped.player_api_id\n                            GROUP BY calc_height\n                            ORDER BY calc_height\n                                ;\"\"\", conn)\nplayers_height","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"3c06ab2d-d93c-4cf0-a8b8-55df5753e24f","_kg_hide-input":true,"_uuid":"391bd233403a29cc9be121f12afcaeae83a20952","collapsed":true,"trusted":true},"cell_type":"code","source":"players_height.plot(x=['calc_height'],y=['avg_overall_rating'],figsize=(12,5),title='Potential vs Height')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}